{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from Modules import LineDetection, OCRInference\n",
    "from Utils import create_dir, get_file_name, batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image: np.array):\n",
    "    display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_model_config = \"Models/LineModels/line_model_config.json\"\n",
    "ocr_model_config = \"Models/OCRModels/LhasaKanjur/ocr_model_config.json\"\n",
    "line_inference = LineDetection(config_file=line_model_config, binarize_output=False)\n",
    "ocr_inference = OCRInference(config_file=ocr_model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr(image_path: str, out_path: str, save_preview: bool = False):\n",
    "    image_name = get_file_name(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    prediction, line_images, sorted_contours, peaks = line_inference.predict(image, 0)\n",
    "    predicted_text, raw_prediction = ocr_inference.run(line_images)\n",
    "    \n",
    "    out_text = f\"{out_path}/{image_name}.txt\"\n",
    "\n",
    "    with open(out_text, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in predicted_text:\n",
    "            f.write(f\"{line}\\n\")\n",
    "\n",
    "    if save_preview:\n",
    "        prediction = cv2.cvtColor(prediction, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.addWeighted(prediction, 0.4, image, 1-0.4, 0, image)\n",
    "        out_prediction = f\"{out_path}/{image_name}_prediction.jpg\"\n",
    "        cv2.imwrite(out_prediction, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Utils import resize_image, pad_image, patch_image\n",
    "import onnxruntime as ort\n",
    "patch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = open(line_model_config)\n",
    "json_content = json.loads(model_file.read())\n",
    "onnx_model_file = json_content[\"cpu-model\"]\n",
    "\n",
    "line_inference = ort.InferenceSession(onnx_model_file, providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 932\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "image_path = \"Data\\W26071-v56\"\n",
    "images = glob(f\"{image_path}/*.tif\")\n",
    "print(f\"Image: {len(images)}\")\n",
    "\n",
    "out_path = os.path.join(image_path, \"predictions\")\n",
    "create_dir(out_path)\n",
    "\n",
    "batched_images = batch_data(images)\n",
    "print(len(batched_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "image_batch = batched_images[1]\n",
    "b_size = image_batch.shape[0]\n",
    "print(b_size)\n",
    "\n",
    "b_image_names = [get_file_name(x) for x in image_batch]\n",
    "b_images = [cv2.imread(x) for x in image_batch]\n",
    "b_images = [resize_image(x)[0] for x in b_images]\n",
    "b_images = [pad_image(x, patch_size=256) for x in b_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b_size = image_batch.shape[0]\n",
    "b_image_names = [get_file_name(x) for x in image_batch]\n",
    "b_images = [cv2.imread(x) for x in image_batch]\n",
    "b_images = [resize_image(x)[0] for x in b_images]\n",
    "b_images = [pad_image(x, patch_size=256) for x in b_images]\n",
    "image_patches = [patch_image(b_images[x][0], patch_size=256) for x in range(len(b_images))]\n",
    "img_batch = [x[0] for x in image_patches]\n",
    "image_batch = np.vstack(img_batch)\n",
    "image_batch = image_batch.astype(np.float32)\n",
    "image_batch /= 255.0\n",
    "\n",
    "image_batch = np.transpose(image_batch, axes=[0, 3, 1, 2]) \n",
    "\n",
    "ort_batch = ort.OrtValue.ortvalue_from_numpy(image_batch)\n",
    "ocr_results = line_inference.run_with_ort_values([\"output\"], {\"input\": ort_batch})\n",
    "prediction = ocr_results[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5/117 [02:05<46:48, 25.08s/it]"
     ]
    }
   ],
   "source": [
    "for b_idx, image_batch in tqdm(enumerate(batched_images), total=len(batched_images)):\n",
    "    b_size = image_batch.shape[0]\n",
    "    b_image_names = [get_file_name(x) for x in image_batch]\n",
    "    b_images = [cv2.imread(x) for x in image_batch]\n",
    "    b_images = [resize_image(x)[0] for x in b_images]\n",
    "    b_images = [pad_image(x, patch_size=256) for x in b_images]\n",
    "    \n",
    "    image_patches = [patch_image(b_images[x][0], patch_size=256) for x in range(len(b_images))]\n",
    "    img_batch = [x[0] for x in image_patches]\n",
    "\n",
    "    image_batch = np.vstack(img_batch)\n",
    "    image_batch = image_batch.astype(np.float32)\n",
    "    image_batch /= 255.0\n",
    "\n",
    "    image_batch = np.transpose(image_batch, axes=[0, 3, 1, 2]) \n",
    "\n",
    "    ort_batch = ort.OrtValue.ortvalue_from_numpy(image_batch)\n",
    "    ocr_results = line_inference.run_with_ort_values([\"output\"], {\"input\": ort_batch})\n",
    "    prediction = ocr_results[0].numpy()\n",
    "    #predicted_text, raw_prediction = ocr_inference.run(line_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]2023-09-21 13:03:07.267649: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "100%|██████████| 7/7 [00:30<00:00,  4.38s/it]\n"
     ]
    }
   ],
   "source": [
    "#run patched prediction\n",
    "for _, image_path in tqdm(enumerate(images), total=len(images)):\n",
    "    run_ocr(image_path, out_path, save_preview=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run OCR on Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_inference = LineDetection(config_file=line_model_config, dilate_kernel=10, dilate_iterations=10, binarize_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 6\n"
     ]
    }
   ],
   "source": [
    "image_path = \"Data\\W2DB4577\"\n",
    "images = glob(f\"{image_path}/*.jpg\")\n",
    "print(f\"Image: {len(images)}\")\n",
    "\n",
    "out_path = os.path.join(image_path, \"predictions\")\n",
    "create_dir(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:56<00:00,  9.46s/it]\n"
     ]
    }
   ],
   "source": [
    "for _, image_path in tqdm(enumerate(images), total=len(images)):\n",
    "    run_ocr(image_path, out_path, save_preview=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run OCR on Testset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 6\n"
     ]
    }
   ],
   "source": [
    "line_inference = LineDetection(config_file=line_model_config, dilate_kernel=10, dilate_iterations=10, binarize_output=False)\n",
    "\n",
    "image_path = \"Data\\W26071-v56\"\n",
    "images = glob(f\"{image_path}/*.jpg\")\n",
    "print(f\"Image: {len(images)}\")\n",
    "\n",
    "out_path = os.path.join(image_path, \"predictions\")\n",
    "create_dir(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
